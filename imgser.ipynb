{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dataset is instrumental for Optical Character Recognition (OCR)\n",
      "tasks because it enables the model to learn and understand various\n",
      "fonts, sizes, and orientations of text. This in turn leads to improved\n",
      "OCR accuracy in real-world applications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "img = Image.open(\"/Users/sasanksasi/Downloads/project/img search gorq/image.png\")\n",
    "\n",
    "# Perform OCR\n",
    "text = pytesseract.image_to_string(img)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's correct! A dataset is crucial for Optical Character Recognition (OCR) tasks because it provides the model with a diverse set of examples to learn from. By analyzing a large dataset, an OCR model can learn to recognize and distinguish various fonts, sizes, and orientations of text, which is essential for achieving high accuracy in real-world applications.\n",
      "\n",
      "A dataset for OCR typically includes images of text in various contexts, such as:\n",
      "\n",
      "* Different fonts (e.g., serif, sans-serif, script)\n",
      "* Varying font sizes (e.g., small, medium, large)\n",
      "* Different orientations (e.g., upright, rotated, mirrored)\n",
      "* Multiple languages and scripts\n",
      "* Images with noise, distortion, or compression artifacts\n",
      "\n",
      "By training on a dataset that includes these variations, an OCR model can learn to:\n",
      "\n",
      "1. Recognize and distinguish between different fonts and font styles\n",
      "2. Handle text of varying sizes and resolutions\n",
      "3. Adapt to different text orientations and layouts\n",
      "4. Compensate for noise and distortion in images\n",
      "5. Recognize text in different languages and scripts\n",
      "\n",
      "As a result, an OCR model trained on a comprehensive dataset can achieve high accuracy in real-world applications, such as:\n",
      "\n",
      "* Document scanning and digitization\n",
      "* Image processing and analysis\n",
      "* Text recognition in historical documents and archives\n",
      "* Automated processing of forms and documents\n",
      "\n",
      "In summary, a dataset is essential for OCR tasks because it enables the model to learn and understand the diverse patterns and variations found in text, leading to improved accuracy and reliability in real-world applications.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from requests.exceptions import ConnectionError, Timeout, RequestException\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "\n",
    "# Set your Gorq AI API key\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"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\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"GROQ_API_KEY is not set. Please set your API key.\")\n",
    "\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "\n",
    "@retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(5))\n",
    "def get_chat_completion():\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text,\n",
    "                }\n",
    "            ],\n",
    "            model=\"llama3-8b-8192\",\n",
    "        )\n",
    "        return chat_completion\n",
    "    except ConnectionError:\n",
    "        print(\"Error: Failed to connect to the server. Retrying...\")\n",
    "        raise\n",
    "    except Timeout:\n",
    "        print(\"Error: The request timed out. Retrying...\")\n",
    "        raise\n",
    "    except RequestException as e:\n",
    "        print(f\"Error: An error occurred. {e}\")\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    chat_completion = get_chat_completion()\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"Failed after several retries: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 00:36:54,101 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's absolutely correct! A high-quality dataset is crucial for training an Optical Character Recognition (OCR) model. A dataset with a diverse range of fonts, sizes, and orientations of text enables the model to learn and generalize well to real-world applications. This is because the model can learn to recognize patterns and characteristics of text in various fonts, sizes, and orientations, which improves its ability to accurately recognize text in diverse scenarios.\n",
      "\n",
      "In particular, having a dataset with:\n",
      "\n",
      "1. **Variety of fonts**: A dataset with multiple fonts, including serif, sans-serif, cursive, and others, helps the model learn to recognize text in different font styles.\n",
      "2. **Multiple sizes**: A dataset with text in different sizes, from small to large, enables the model to learn to recognize text at varying scales.\n",
      "3. **Orientations**: A dataset with text in different orientations, such as horizontal, vertical, and diagonal, helps the model learn to recognize text regardless of its orientation.\n",
      "\n",
      "By training on a diverse dataset, an OCR model can develop robustness to variations in text appearance, which leads to improved accuracy in real-world applications, such as:\n",
      "\n",
      "1. Document scanning and digitization\n",
      "2. Image processing and analysis\n",
      "3. Web scraping and text extraction\n",
      "4. Document recognition and processing\n",
      "\n",
      "Overall, a high-quality dataset is essential for building an accurate and robust OCR model that can effectively recognize text in various contexts.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from groq import Groq\n",
    "from requests.exceptions import ConnectionError, Timeout, RequestException\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "import pickle\n",
    "\n",
    "# Set your Gorq AI API key\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"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\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"GROQ_API_KEY is not set. Please set your API key.\")\n",
    "\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "\n",
    "@retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(5))\n",
    "def get_chat_completion(text):\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text,\n",
    "                }\n",
    "            ],\n",
    "            model=\"llama3-8b-8192\",\n",
    "        )\n",
    "        return chat_completion\n",
    "    except ConnectionError:\n",
    "        print(\"Error: Failed to connect to the server. Retrying...\")\n",
    "        raise\n",
    "    except Timeout:\n",
    "        print(\"Error: The request timed out. Retrying...\")\n",
    "        raise\n",
    "    except RequestException as e:\n",
    "        print(f\"Error: An error occurred. {e}\")\n",
    "        raise\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Perform OCR\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def process_image(image_path):\n",
    "    text = extract_text_from_image(image_path)\n",
    "    if text:\n",
    "        try:\n",
    "            chat_completion = get_chat_completion(text)\n",
    "            print(chat_completion.choices[0].message.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed after several retries: {e}\")\n",
    "    else:\n",
    "        print(\"No text found in the image.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"/Users/sasanksasi/Downloads/project/img search gorq/image.png\"\n",
    "    process_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 00:41:13,043 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's correct! A dataset is crucial for Optical Character Recognition (OCR) tasks because it allows the model to learn and recognize various fonts, sizes, and orientations of text. A well-curated dataset can help the model generalize to real-world situations and improve its accuracy.\n",
      "\n",
      "A dataset for OCR tasks typically includes a large collection of images of text, along with their corresponding transcriptions. This dataset is used to train the OCR model, which learns to recognize the patterns and structures of text in the images.\n",
      "\n",
      "Having a diverse dataset with examples of different fonts, sizes, and orientations is essential because it helps the model to develop the following skills:\n",
      "\n",
      "1. **Font recognition**: The model learns to recognize different fonts, including serif, sans-serif, script, and more.\n",
      "2. **Size variation**: The model learns to recognize text of varying sizes, including small text, large text, and text with varying line heights.\n",
      "3. **Orientation recognition**: The model learns to recognize text written in different orientations, such as horizontal, vertical, and diagonal.\n",
      "\n",
      "By learning from these variations, the OCR model becomes more robust and accurate in real-world applications, where text can appear in a wide range of fonts, sizes, and orientations.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from groq import Groq\n",
    "from requests.exceptions import ConnectionError, Timeout, RequestException\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "import pickle\n",
    "\n",
    "# Set your Gorq AI API key\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"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\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"GROQ_API_KEY is not set. Please set your API key.\")\n",
    "\n",
    "class ImageToTextPipeline:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.client = Groq(api_key=self.api_key)\n",
    "\n",
    "    @retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(5))\n",
    "    def get_chat_completion(self, text):\n",
    "        try:\n",
    "            chat_completion = self.client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": text,\n",
    "                    }\n",
    "                ],\n",
    "                model=\"llama3-8b-8192\",\n",
    "            )\n",
    "            return chat_completion\n",
    "        except ConnectionError:\n",
    "            print(\"Error: Failed to connect to the server. Retrying...\")\n",
    "            raise\n",
    "        except Timeout:\n",
    "            print(\"Error: The request timed out. Retrying...\")\n",
    "            raise\n",
    "        except RequestException as e:\n",
    "            print(f\"Error: An error occurred. {e}\")\n",
    "            raise\n",
    "\n",
    "    def extract_text_from_image(self, image_path):\n",
    "        # Load the image\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # Perform OCR\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        text = self.extract_text_from_image(image_path)\n",
    "        if text:\n",
    "            try:\n",
    "                chat_completion = self.get_chat_completion(text)\n",
    "                print(chat_completion.choices[0].message.content)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed after several retries: {e}\")\n",
    "        else:\n",
    "            print(\"No text found in the image.\")\n",
    "\n",
    "    def save_pipeline(self, filename):\n",
    "        # Temporarily remove the client before pickling\n",
    "        client = self.client\n",
    "        self.client = None\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        # Restore the client\n",
    "        self.client = client\n",
    "\n",
    "    @classmethod\n",
    "    def load_pipeline(cls, filename, api_key):\n",
    "        with open(filename, 'rb') as f:\n",
    "            pipeline = pickle.load(f)\n",
    "        # Reinitialize the client\n",
    "        pipeline.client = Groq(api_key=api_key)\n",
    "        return pipeline\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = os.getenv(\"GROQ_API_KEY\", \"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\")\n",
    "    pipeline = ImageToTextPipeline(api_key)\n",
    "    \n",
    "    # Get the image path from the user\n",
    "    image_path = input(\"Please enter the path to the image: \")\n",
    "    \n",
    "    # Process the image\n",
    "    pipeline.process_image(image_path)\n",
    "\n",
    "    # Save the pipeline\n",
    "    pipeline.save_pipeline('pipeline.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Load the pipeline and process another image\n",
    "loaded_pipeline = ImageToTextPipeline.load_pipeline('pipeline.pkl', api_key)\n",
    "image_path = input(\"Please enter the path to another image: \")\n",
    "loaded_pipeline.process_image(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
