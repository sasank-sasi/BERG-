{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dataset is instrumental for Optical Character Recognition (OCR)\n",
      "tasks because it enables the model to learn and understand various\n",
      "fonts, sizes, and orientations of text. This in turn leads to improved\n",
      "OCR accuracy in real-world applications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "img = Image.open(\"image.png\")\n",
    "\n",
    "# Perform OCR\n",
    "text = pytesseract.image_to_string(img)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's correct! A dataset plays a crucial role in Optical Character Recognition (OCR) tasks. A well-curated dataset allows the model to learn and understand various aspects of text, including:\n",
      "\n",
      "1. Fonts: Different fonts, such as serif, sans-serif, and script, may require specific features and patterns to be accurately recognized.\n",
      "2. Sizes: Text of varying sizes, from tiny to large, can have distinct characteristics that the model needs to learn to recognize.\n",
      "3. Orientations: Text can be written at different angles, such as upright, tilted, or even rotated, which requires the model to generalize to different orientations.\n",
      "\n",
      "By training on a diverse dataset that covers these variations, an OCR model can improve its accuracy in real-world applications. A dataset with a large variety of fonts, sizes, and orientations can help the model learn robust features that enable it to recognize text in different scenarios.\n",
      "\n",
      "Some examples of OCR datasets that are commonly used for training models include:\n",
      "\n",
      "1. MNIST: A popular dataset for handwritten digit recognition.\n",
      "2. ICdar: A dataset for text recognition in documents, which includes multiple languages and font styles.\n",
      "3. SVHN: A dataset for street view house numbers recognition, which includes text recognition in images.\n",
      "\n",
      "By training on a comprehensive dataset, OCR models can achieve higher accuracy and improve their ability to recognize text in real-world applications, such as document scanning, image recognition, and more.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from requests.exceptions import ConnectionError, Timeout, RequestException\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "\n",
    "# Set your Gorq AI API key\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"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\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"GROQ_API_KEY is not set. Please set your API key.\")\n",
    "\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "\n",
    "@retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(5))\n",
    "def get_chat_completion():\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text,\n",
    "                }\n",
    "            ],\n",
    "            model=\"llama3-8b-8192\",\n",
    "        )\n",
    "        return chat_completion\n",
    "    except ConnectionError:\n",
    "        print(\"Error: Failed to connect to the server. Retrying...\")\n",
    "        raise\n",
    "    except Timeout:\n",
    "        print(\"Error: The request timed out. Retrying...\")\n",
    "        raise\n",
    "    except RequestException as e:\n",
    "        print(f\"Error: An error occurred. {e}\")\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    chat_completion = get_chat_completion()\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"Failed after several retries: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's absolutely correct! A dataset is crucial for Optical Character Recognition (OCR) tasks because it provides the model with a comprehensive range of examples to learn from. By including various fonts, sizes, and orientations of text, the dataset helps the model develop a robust understanding of how to recognize and classify characters from diverse sources.\n",
      "\n",
      "Having a large and diverse dataset allows the OCR model to learn the following:\n",
      "\n",
      "1. **Font variability**: The dataset exposes the model to different fonts, which enables it to recognize characters even if they are not presented in the same font as the training data.\n",
      "2. **Size variability**: The model learns to recognize characters in different sizes, which is important for OCR systems that need to process text from documents or images with varying font sizes.\n",
      "3. **Orientation variability**: The dataset includes characters in different orientations, such as horizontal, vertical, and diagonal, helping the model understand how to recognize text even if it's not aligned properly.\n",
      "4. **Noise and degradation**: The dataset may include images of characters with noise, blurring, or other forms of degradation, allowing the model to learn how to handle these real-world challenges.\n",
      "\n",
      "By providing the model with a comprehensive dataset, you can significantly improve OCR accuracy and ensure that the system can recognize text in a wide range of scenarios and applications.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from groq import Groq\n",
    "from requests.exceptions import ConnectionError, Timeout, RequestException\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "import pickle\n",
    "\n",
    "# Set your Gorq AI API key\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"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\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"GROQ_API_KEY is not set. Please set your API key.\")\n",
    "\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "\n",
    "@retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(5))\n",
    "def get_chat_completion(text):\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text,\n",
    "                }\n",
    "            ],\n",
    "            model=\"llama3-8b-8192\",\n",
    "        )\n",
    "        return chat_completion\n",
    "    except ConnectionError:\n",
    "        print(\"Error: Failed to connect to the server. Retrying...\")\n",
    "        raise\n",
    "    except Timeout:\n",
    "        print(\"Error: The request timed out. Retrying...\")\n",
    "        raise\n",
    "    except RequestException as e:\n",
    "        print(f\"Error: An error occurred. {e}\")\n",
    "        raise\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Perform OCR\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def process_image(image_path):\n",
    "    text = extract_text_from_image(image_path)\n",
    "    if text:\n",
    "        try:\n",
    "            chat_completion = get_chat_completion(text)\n",
    "            print(chat_completion.choices[0].message.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed after several retries: {e}\")\n",
    "    else:\n",
    "        print(\"No text found in the image.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"image.png\"\n",
    "    process_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's correct! A dataset is crucial for optical character recognition (OCR) tasks as it provides the model with a large amount of labeled data to learn from. This labeled data includes examples of text in various fonts, sizes, and orientations, which helps the model train and become proficient in recognizing and understanding different types of text.\n",
      "\n",
      "With a well-curated dataset, the OCR model can learn to:\n",
      "\n",
      "1. Identify and recognize various fonts, including serif, sans-serif, script, and decorative fonts.\n",
      "2. Handle text in different sizes, ranging from tiny headings to large body text.\n",
      "3. Recognize text in different orientations, including upright text, rotated text, and text with skewing.\n",
      "4. Detect and correct common OCR errors, such as character substitutions, insertions, and deletions.\n",
      "\n",
      "By training the model on a large and diverse dataset, the model becomes more accurate and robust, which leads to improved OCR performance in real-world applications, such as:\n",
      "\n",
      "1. Document scanning and digitization\n",
      "2. Image recognition and classification\n",
      "3. Automatic data extraction and processing\n",
      "4. Language translation and text analysis\n",
      "\n",
      "In summary, a dataset is instrumental for OCR tasks as it enables the model to learn and understand various aspects of text, leading to improved accuracy and performance in real-world applications.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from groq import Groq\n",
    "from requests.exceptions import ConnectionError, Timeout, RequestException\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "import pickle\n",
    "\n",
    "# Set your Gorq AI API key\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"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\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"GROQ_API_KEY is not set. Please set your API key.\")\n",
    "\n",
    "class ImageToTextPipeline:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.client = Groq(api_key=self.api_key)\n",
    "\n",
    "    @retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(5))\n",
    "    def get_chat_completion(self, text):\n",
    "        try:\n",
    "            chat_completion = self.client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": text,\n",
    "                    }\n",
    "                ],\n",
    "                model=\"llama3-8b-8192\",\n",
    "            )\n",
    "            return chat_completion\n",
    "        except ConnectionError:\n",
    "            print(\"Error: Failed to connect to the server. Retrying...\")\n",
    "            raise\n",
    "        except Timeout:\n",
    "            print(\"Error: The request timed out. Retrying...\")\n",
    "            raise\n",
    "        except RequestException as e:\n",
    "            print(f\"Error: An error occurred. {e}\")\n",
    "            raise\n",
    "\n",
    "    def extract_text_from_image(self, image_path):\n",
    "        # Load the image\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # Perform OCR\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        text = self.extract_text_from_image(image_path)\n",
    "        if text:\n",
    "            try:\n",
    "                chat_completion = self.get_chat_completion(text)\n",
    "                print(chat_completion.choices[0].message.content)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed after several retries: {e}\")\n",
    "        else:\n",
    "            print(\"No text found in the image.\")\n",
    "\n",
    "    def save_pipeline(self, filename):\n",
    "        # Temporarily remove the client before pickling\n",
    "        client = self.client\n",
    "        self.client = None\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        # Restore the client\n",
    "        self.client = client\n",
    "\n",
    "    @classmethod\n",
    "    def load_pipeline(cls, filename, api_key):\n",
    "        with open(filename, 'rb') as f:\n",
    "            pipeline = pickle.load(f)\n",
    "        # Reinitialize the client\n",
    "        pipeline.client = Groq(api_key=api_key)\n",
    "        return pipeline\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = os.getenv(\"GROQ_API_KEY\", \"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\")\n",
    "    pipeline = ImageToTextPipeline(api_key)\n",
    "    \n",
    "    # Get the image path from the user\n",
    "    image_path = input(\"Please enter the path to the image: \")\n",
    "    \n",
    "    # Process the image\n",
    "    pipeline.process_image(image_path)\n",
    "\n",
    "    # Save the pipeline\n",
    "    pipeline.save_pipeline('vatta.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It appears to be a cancelled cheque issued by the State Bank of India in favor of NAGAMALLI ENCLAVE FLAT OWNERS‘ ASSOCIATION VSP.\n",
      "\n",
      "The details on the cheque are as follows:\n",
      "\n",
      "* Account No: 10849853744\n",
      "* Customer Name: NAGAMALLI ENCLAVE FLAT OWNERS‘ ASSOCIATION VSP\n",
      "* Address: 14-25-16, F-3RD FLOOR, NAGAMALLI ENCLAVE, MAHARANIPETA\n",
      "* Phone: 2551284\n",
      "* Email: SA.00754@SBI.CO\n",
      "* Branch Code: 754 (Visakhapatnam branch)\n",
      "* Date of Issue: 20/07/2018\n",
      "* Amount: ₹87,009.00\n",
      "\n",
      "The back of the cheque appears to be a registration form for a nomination, but it seems to be incomplete and has some handwritten notes and corrections.\n"
     ]
    }
   ],
   "source": [
    "    # Load the pipeline and process another image\n",
    "loaded_pipeline = ImageToTextPipeline.load_pipeline('vatta.pkl', api_key)\n",
    "image_path = input(\"Please enter the path to another image: \")\n",
    "loaded_pipeline.process_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
